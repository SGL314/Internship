{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hiZVkjn822t"
      },
      "source": [
        "Nesta aula, vamos aprender como trabalhar com ngramas e stopwords, utilizando a bilioteca NLTK."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6u3zkx7T73M5"
      },
      "source": [
        "# NGRAMAS, Stopwords e NLTK\n",
        "### Autor: Lucas Ferro Antunes de Oliveira\n",
        "#### HAILab - PPGTS - PUCPR\n",
        "\n",
        "lucas.ferro.2000@hotmail.com"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42YvY7xA-PpC"
      },
      "source": [
        "#Tokenização e normalização do corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "nuuBHqPCO0sy"
      },
      "outputs": [],
      "source": [
        "import nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "Wkn-uW7s-RYa",
        "outputId": "8d0d809c-85bd-451f-f6a2-28fd779caf15"
      },
      "outputs": [],
      "source": [
        "# Instalação do NLTK\n",
        "# !pip install nltk==3.6.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MSXZ4bVf8HAH",
        "outputId": "8f5b97e6-8df8-418c-c7cc-cc70373160d4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\samug\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 99,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Importação de bibliotecas\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize,sent_tokenize\n",
        "from datetime import datetime\n",
        "from collections import Counter\n",
        "from nltk import ngrams\n",
        "import string\n",
        "from wordcloud import WordCloud,STOPWORDS,ImageColorGenerator\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import re\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Converte o .pdf em .txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "0ydiU8zL8HGW"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cap 1: ['1', '1', '.', '\\n'] : 0\n",
            "cap 2: ['1', '2', '.', '\\n'] : 1\n",
            "cap 3: ['1', '3', '.', '\\n'] : 2\n",
            "cap 4: ['1', '4', '.', '\\n'] : 3\n",
            "cap 5: ['1', '5', '.', '\\n'] : 4\n",
            "cap 6: ['1', '6', '.', '\\n'] : 5\n",
            "cap 7: ['1', '7', '.', '\\n'] : 6\n",
            "cap 8: ['1', '8', '.', '\\n'] : 7\n",
            "cap 9: ['1', '9', '.', '\\n'] : 8\n",
            "cap 10: ['1', '1', '0', '.'] : 9\n"
          ]
        }
      ],
      "source": [
        "# pd.set_option('max_columns', None)\n",
        "# pd.set_option('max_colwidth', None)\n",
        "from PyPDF2 import PdfReader\n",
        "\n",
        "# Transforma .pdf em .txt\n",
        "file = \"aRevolucaoDosBichos\"\n",
        "PATH = \"content/\"\n",
        "reader = PdfReader(PATH+\"\"+file+\".pdf\")\n",
        "qt = 0\n",
        "last = 0\n",
        "\n",
        "with open(PATH+\"txt_cap1.txt\",'w',encoding=\"utf-8\") as txt_file:\n",
        "    for page_num in range(len(reader.pages)):\n",
        "        page = reader.pages[page_num]\n",
        "        text = page.extract_text()\n",
        "        # verifica passagem de capítulo\n",
        "        block = [\"1\",\"1\",\"1\",\"1\"]\n",
        "        result = \"\"\n",
        "        ardb = open(PATH+\"ardb.txt\",\"a\",encoding=\"utf-8\")\n",
        "        # ardb.write(text) # +\"\\n\\n\\n\\n\\n ------------------------------------------------------------------------ \\n\\n\\n\\n\\n\"\n",
        "        for char in text:\n",
        "            block[0] = block[1]\n",
        "            block[1] = block[2]\n",
        "            block[2] = block[3]\n",
        "            block[3] = char\n",
        "            {\n",
        "                # qt+=1\n",
        "                # if (qt >= 14491) :\n",
        "                # ardb.write(f\"{block}\\n\")\n",
        "            }            \n",
        "            for num in range(1,11):\n",
        "                if ((block[1] == f\"{num}\" and block[2] == \".\" and block[3] == \"\\n\") or (block[1] == \"1\" and block[2] == \"0\" and block[3] == \".\" and num==10)):\n",
        "                    if last>num: #para não colocar o conteúdo num capítulo anterior detectado\n",
        "                        break\n",
        "                    print(f\"cap {num}: {block} : {last}\")\n",
        "                    last = num\n",
        "                    txt_file = open(PATH+f\"txt_cap{num}.txt\",\"w\",encoding=\"utf-8\")\n",
        "        txt_file.write(text)\n",
        "#"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "UV21w1US8HJG",
        "outputId": "a3b5bc77-f197-40e6-8a13-432bec5c52c0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
            ]
          },
          "execution_count": 101,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Pega todas as pontuações\n",
        "remove_pt = string.punctuation\n",
        "remove_pt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gjd4QLA88HLe",
        "outputId": "66f2c685-ddb2-4dfb-e7c4-a3b626699209"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\samug\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'a',\n",
              " 'ao',\n",
              " 'aos',\n",
              " 'aquela',\n",
              " 'aquelas',\n",
              " 'aquele',\n",
              " 'aqueles',\n",
              " 'aquilo',\n",
              " 'as',\n",
              " 'até',\n",
              " 'com',\n",
              " 'como',\n",
              " 'da',\n",
              " 'das',\n",
              " 'de',\n",
              " 'dela',\n",
              " 'delas',\n",
              " 'dele',\n",
              " 'deles',\n",
              " 'depois',\n",
              " 'do',\n",
              " 'dos',\n",
              " 'e',\n",
              " 'ela',\n",
              " 'elas',\n",
              " 'ele',\n",
              " 'eles',\n",
              " 'em',\n",
              " 'entre',\n",
              " 'era',\n",
              " 'eram',\n",
              " 'essa',\n",
              " 'essas',\n",
              " 'esse',\n",
              " 'esses',\n",
              " 'esta',\n",
              " 'estamos',\n",
              " 'estar',\n",
              " 'estas',\n",
              " 'estava',\n",
              " 'estavam',\n",
              " 'este',\n",
              " 'esteja',\n",
              " 'estejam',\n",
              " 'estejamos',\n",
              " 'estes',\n",
              " 'esteve',\n",
              " 'estive',\n",
              " 'estivemos',\n",
              " 'estiver',\n",
              " 'estivera',\n",
              " 'estiveram',\n",
              " 'estiverem',\n",
              " 'estivermos',\n",
              " 'estivesse',\n",
              " 'estivessem',\n",
              " 'estivéramos',\n",
              " 'estivéssemos',\n",
              " 'estou',\n",
              " 'está',\n",
              " 'estávamos',\n",
              " 'estão',\n",
              " 'eu',\n",
              " 'foi',\n",
              " 'fomos',\n",
              " 'for',\n",
              " 'fora',\n",
              " 'foram',\n",
              " 'forem',\n",
              " 'formos',\n",
              " 'fosse',\n",
              " 'fossem',\n",
              " 'fui',\n",
              " 'fôramos',\n",
              " 'fôssemos',\n",
              " 'haja',\n",
              " 'hajam',\n",
              " 'hajamos',\n",
              " 'havemos',\n",
              " 'haver',\n",
              " 'hei',\n",
              " 'houve',\n",
              " 'houvemos',\n",
              " 'houver',\n",
              " 'houvera',\n",
              " 'houveram',\n",
              " 'houverei',\n",
              " 'houverem',\n",
              " 'houveremos',\n",
              " 'houveria',\n",
              " 'houveriam',\n",
              " 'houvermos',\n",
              " 'houverá',\n",
              " 'houverão',\n",
              " 'houveríamos',\n",
              " 'houvesse',\n",
              " 'houvessem',\n",
              " 'houvéramos',\n",
              " 'houvéssemos',\n",
              " 'há',\n",
              " 'hão',\n",
              " 'isso',\n",
              " 'isto',\n",
              " 'já',\n",
              " 'lhe',\n",
              " 'lhes',\n",
              " 'mais',\n",
              " 'mas',\n",
              " 'me',\n",
              " 'mesmo',\n",
              " 'meu',\n",
              " 'meus',\n",
              " 'minha',\n",
              " 'minhas',\n",
              " 'muito',\n",
              " 'na',\n",
              " 'nas',\n",
              " 'nem',\n",
              " 'no',\n",
              " 'nos',\n",
              " 'nossa',\n",
              " 'nossas',\n",
              " 'nosso',\n",
              " 'nossos',\n",
              " 'num',\n",
              " 'numa',\n",
              " 'não',\n",
              " 'nós',\n",
              " 'o',\n",
              " 'os',\n",
              " 'ou',\n",
              " 'para',\n",
              " 'pela',\n",
              " 'pelas',\n",
              " 'pelo',\n",
              " 'pelos',\n",
              " 'por',\n",
              " 'qual',\n",
              " 'quando',\n",
              " 'que',\n",
              " 'quem',\n",
              " 'se',\n",
              " 'seja',\n",
              " 'sejam',\n",
              " 'sejamos',\n",
              " 'sem',\n",
              " 'ser',\n",
              " 'serei',\n",
              " 'seremos',\n",
              " 'seria',\n",
              " 'seriam',\n",
              " 'será',\n",
              " 'serão',\n",
              " 'seríamos',\n",
              " 'seu',\n",
              " 'seus',\n",
              " 'somos',\n",
              " 'sou',\n",
              " 'sua',\n",
              " 'suas',\n",
              " 'são',\n",
              " 'só',\n",
              " 'também',\n",
              " 'te',\n",
              " 'tem',\n",
              " 'temos',\n",
              " 'tenha',\n",
              " 'tenham',\n",
              " 'tenhamos',\n",
              " 'tenho',\n",
              " 'terei',\n",
              " 'teremos',\n",
              " 'teria',\n",
              " 'teriam',\n",
              " 'terá',\n",
              " 'terão',\n",
              " 'teríamos',\n",
              " 'teu',\n",
              " 'teus',\n",
              " 'teve',\n",
              " 'tinha',\n",
              " 'tinham',\n",
              " 'tive',\n",
              " 'tivemos',\n",
              " 'tiver',\n",
              " 'tivera',\n",
              " 'tiveram',\n",
              " 'tiverem',\n",
              " 'tivermos',\n",
              " 'tivesse',\n",
              " 'tivessem',\n",
              " 'tivéramos',\n",
              " 'tivéssemos',\n",
              " 'tu',\n",
              " 'tua',\n",
              " 'tuas',\n",
              " 'tém',\n",
              " 'tínhamos',\n",
              " 'um',\n",
              " 'uma',\n",
              " 'você',\n",
              " 'vocês',\n",
              " 'vos',\n",
              " 'à',\n",
              " 'às',\n",
              " 'é',\n",
              " 'éramos'}"
            ]
          },
          "execution_count": 102,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Baixa as stopwords para o português no NLTK\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "stop_words_pt = set(stopwords.words('portuguese'))\n",
        "len(stop_words_pt)\n",
        "stop_words_pt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87i9Qfc685w3",
        "outputId": "c21de7b2-436c-4517-a8c5-05b5f777f58c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'a',\n",
              " 'ao',\n",
              " 'aos',\n",
              " 'aquela',\n",
              " 'aquelas',\n",
              " 'aquele',\n",
              " 'aqueles',\n",
              " 'aquilo',\n",
              " 'as',\n",
              " 'até',\n",
              " 'com',\n",
              " 'como',\n",
              " 'da',\n",
              " 'das',\n",
              " 'de',\n",
              " 'dela',\n",
              " 'delas',\n",
              " 'dele',\n",
              " 'deles',\n",
              " 'depois',\n",
              " 'do',\n",
              " 'dos',\n",
              " 'e',\n",
              " 'ela',\n",
              " 'elas',\n",
              " 'ele',\n",
              " 'eles',\n",
              " 'em',\n",
              " 'entao',\n",
              " 'entre',\n",
              " 'era',\n",
              " 'eram',\n",
              " 'essa',\n",
              " 'essas',\n",
              " 'esse',\n",
              " 'esses',\n",
              " 'esta',\n",
              " 'estamos',\n",
              " 'estar',\n",
              " 'estas',\n",
              " 'estava',\n",
              " 'estavam',\n",
              " 'este',\n",
              " 'esteja',\n",
              " 'estejam',\n",
              " 'estejamos',\n",
              " 'estes',\n",
              " 'esteve',\n",
              " 'estive',\n",
              " 'estivemos',\n",
              " 'estiver',\n",
              " 'estivera',\n",
              " 'estiveram',\n",
              " 'estiverem',\n",
              " 'estivermos',\n",
              " 'estivesse',\n",
              " 'estivessem',\n",
              " 'estivéramos',\n",
              " 'estivéssemos',\n",
              " 'estou',\n",
              " 'está',\n",
              " 'estávamos',\n",
              " 'estão',\n",
              " 'eu',\n",
              " 'foi',\n",
              " 'fomos',\n",
              " 'for',\n",
              " 'fora',\n",
              " 'foram',\n",
              " 'forem',\n",
              " 'formos',\n",
              " 'fosse',\n",
              " 'fossem',\n",
              " 'fui',\n",
              " 'fôramos',\n",
              " 'fôssemos',\n",
              " 'haja',\n",
              " 'hajam',\n",
              " 'hajamos',\n",
              " 'havemos',\n",
              " 'haver',\n",
              " 'hei',\n",
              " 'houve',\n",
              " 'houvemos',\n",
              " 'houver',\n",
              " 'houvera',\n",
              " 'houveram',\n",
              " 'houverei',\n",
              " 'houverem',\n",
              " 'houveremos',\n",
              " 'houveria',\n",
              " 'houveriam',\n",
              " 'houvermos',\n",
              " 'houverá',\n",
              " 'houverão',\n",
              " 'houveríamos',\n",
              " 'houvesse',\n",
              " 'houvessem',\n",
              " 'houvéramos',\n",
              " 'houvéssemos',\n",
              " 'há',\n",
              " 'hão',\n",
              " 'isso',\n",
              " 'isto',\n",
              " 'já',\n",
              " 'lhe',\n",
              " 'lhes',\n",
              " 'mais',\n",
              " 'mas',\n",
              " 'me',\n",
              " 'mesmo',\n",
              " 'meu',\n",
              " 'meus',\n",
              " 'minha',\n",
              " 'minhas',\n",
              " 'muito',\n",
              " 'na',\n",
              " 'nas',\n",
              " 'nem',\n",
              " 'no',\n",
              " 'nos',\n",
              " 'nossa',\n",
              " 'nossas',\n",
              " 'nosso',\n",
              " 'nossos',\n",
              " 'num',\n",
              " 'numa',\n",
              " 'não',\n",
              " 'nós',\n",
              " 'o',\n",
              " 'os',\n",
              " 'ou',\n",
              " 'para',\n",
              " 'pela',\n",
              " 'pelas',\n",
              " 'pelo',\n",
              " 'pelos',\n",
              " 'por',\n",
              " 'qual',\n",
              " 'quando',\n",
              " 'que',\n",
              " 'quem',\n",
              " 'se',\n",
              " 'seja',\n",
              " 'sejam',\n",
              " 'sejamos',\n",
              " 'sem',\n",
              " 'ser',\n",
              " 'serei',\n",
              " 'seremos',\n",
              " 'seria',\n",
              " 'seriam',\n",
              " 'será',\n",
              " 'serão',\n",
              " 'seríamos',\n",
              " 'seu',\n",
              " 'seus',\n",
              " 'somos',\n",
              " 'sou',\n",
              " 'sua',\n",
              " 'suas',\n",
              " 'são',\n",
              " 'só',\n",
              " 'também',\n",
              " 'te',\n",
              " 'tem',\n",
              " 'temos',\n",
              " 'tenha',\n",
              " 'tenham',\n",
              " 'tenhamos',\n",
              " 'tenho',\n",
              " 'terei',\n",
              " 'teremos',\n",
              " 'teria',\n",
              " 'teriam',\n",
              " 'terá',\n",
              " 'terão',\n",
              " 'teríamos',\n",
              " 'teu',\n",
              " 'teus',\n",
              " 'teve',\n",
              " 'tinha',\n",
              " 'tinham',\n",
              " 'tive',\n",
              " 'tivemos',\n",
              " 'tiver',\n",
              " 'tivera',\n",
              " 'tiveram',\n",
              " 'tiverem',\n",
              " 'tivermos',\n",
              " 'tivesse',\n",
              " 'tivessem',\n",
              " 'tivéramos',\n",
              " 'tivéssemos',\n",
              " 'tu',\n",
              " 'tua',\n",
              " 'tuas',\n",
              " 'tém',\n",
              " 'tínhamos',\n",
              " 'um',\n",
              " 'uma',\n",
              " 'você',\n",
              " 'vocês',\n",
              " 'vos',\n",
              " 'à',\n",
              " 'às',\n",
              " 'é',\n",
              " 'éramos'}"
            ]
          },
          "execution_count": 103,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "stop_words_pt.add('ser')\n",
        "stop_words_pt.add('entao')\n",
        "stop_words_pt.add('de')\n",
        "\n",
        "stop_words_pt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G0c9Kokp8HN-",
        "outputId": "065a4047-2f82-49bd-8c3d-c6c0407cea07"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'a',\n",
              " 'ainda',\n",
              " 'ao',\n",
              " 'aos',\n",
              " 'aquela',\n",
              " 'aquelas',\n",
              " 'aquele',\n",
              " 'aqueles',\n",
              " 'aquilo',\n",
              " 'as',\n",
              " 'até',\n",
              " 'com',\n",
              " 'como',\n",
              " 'da',\n",
              " 'das',\n",
              " 'de',\n",
              " 'dela',\n",
              " 'delas',\n",
              " 'dele',\n",
              " 'deles',\n",
              " 'depois',\n",
              " 'do',\n",
              " 'dos',\n",
              " 'e',\n",
              " 'ela',\n",
              " 'elas',\n",
              " 'ele',\n",
              " 'eles',\n",
              " 'em',\n",
              " 'entao',\n",
              " 'entre',\n",
              " 'era',\n",
              " 'eram',\n",
              " 'essa',\n",
              " 'essas',\n",
              " 'esse',\n",
              " 'esses',\n",
              " 'esta',\n",
              " 'estamos',\n",
              " 'estar',\n",
              " 'estas',\n",
              " 'estava',\n",
              " 'estavam',\n",
              " 'este',\n",
              " 'esteja',\n",
              " 'estejam',\n",
              " 'estejamos',\n",
              " 'estes',\n",
              " 'esteve',\n",
              " 'estive',\n",
              " 'estivemos',\n",
              " 'estiver',\n",
              " 'estivera',\n",
              " 'estiveram',\n",
              " 'estiverem',\n",
              " 'estivermos',\n",
              " 'estivesse',\n",
              " 'estivessem',\n",
              " 'estivéramos',\n",
              " 'estivéssemos',\n",
              " 'estou',\n",
              " 'está',\n",
              " 'estávamos',\n",
              " 'estão',\n",
              " 'eu',\n",
              " 'foi',\n",
              " 'fomos',\n",
              " 'for',\n",
              " 'fora',\n",
              " 'foram',\n",
              " 'forem',\n",
              " 'formos',\n",
              " 'fosse',\n",
              " 'fossem',\n",
              " 'fui',\n",
              " 'fôramos',\n",
              " 'fôssemos',\n",
              " 'haja',\n",
              " 'hajam',\n",
              " 'hajamos',\n",
              " 'havemos',\n",
              " 'haver',\n",
              " 'hei',\n",
              " 'houve',\n",
              " 'houvemos',\n",
              " 'houver',\n",
              " 'houvera',\n",
              " 'houveram',\n",
              " 'houverei',\n",
              " 'houverem',\n",
              " 'houveremos',\n",
              " 'houveria',\n",
              " 'houveriam',\n",
              " 'houvermos',\n",
              " 'houverá',\n",
              " 'houverão',\n",
              " 'houveríamos',\n",
              " 'houvesse',\n",
              " 'houvessem',\n",
              " 'houvéramos',\n",
              " 'houvéssemos',\n",
              " 'há',\n",
              " 'hão',\n",
              " 'isso',\n",
              " 'isto',\n",
              " 'já',\n",
              " 'lhe',\n",
              " 'lhes',\n",
              " 'mais',\n",
              " 'mas',\n",
              " 'me',\n",
              " 'mesmo',\n",
              " 'meu',\n",
              " 'meus',\n",
              " 'minha',\n",
              " 'minhas',\n",
              " 'muito',\n",
              " 'na',\n",
              " 'nas',\n",
              " 'nem',\n",
              " 'no',\n",
              " 'nos',\n",
              " 'nossa',\n",
              " 'nossas',\n",
              " 'nosso',\n",
              " 'nossos',\n",
              " 'num',\n",
              " 'numa',\n",
              " 'não',\n",
              " 'nós',\n",
              " 'o',\n",
              " 'os',\n",
              " 'ou',\n",
              " 'para',\n",
              " 'pela',\n",
              " 'pelas',\n",
              " 'pelo',\n",
              " 'pelos',\n",
              " 'por',\n",
              " 'porém',\n",
              " 'qual',\n",
              " 'quando',\n",
              " 'que',\n",
              " 'quem',\n",
              " 'se',\n",
              " 'seja',\n",
              " 'sejam',\n",
              " 'sejamos',\n",
              " 'sem',\n",
              " 'ser',\n",
              " 'serei',\n",
              " 'seremos',\n",
              " 'seria',\n",
              " 'seriam',\n",
              " 'será',\n",
              " 'serão',\n",
              " 'seríamos',\n",
              " 'seu',\n",
              " 'seus',\n",
              " 'somos',\n",
              " 'sou',\n",
              " 'sua',\n",
              " 'suas',\n",
              " 'são',\n",
              " 'só',\n",
              " 'também',\n",
              " 'te',\n",
              " 'tem',\n",
              " 'temos',\n",
              " 'tenha',\n",
              " 'tenham',\n",
              " 'tenhamos',\n",
              " 'tenho',\n",
              " 'terei',\n",
              " 'teremos',\n",
              " 'teria',\n",
              " 'teriam',\n",
              " 'terá',\n",
              " 'terão',\n",
              " 'teríamos',\n",
              " 'teu',\n",
              " 'teus',\n",
              " 'teve',\n",
              " 'tinha',\n",
              " 'tinham',\n",
              " 'tive',\n",
              " 'tivemos',\n",
              " 'tiver',\n",
              " 'tivera',\n",
              " 'tiveram',\n",
              " 'tiverem',\n",
              " 'tivermos',\n",
              " 'tivesse',\n",
              " 'tivessem',\n",
              " 'tivéramos',\n",
              " 'tivéssemos',\n",
              " 'tu',\n",
              " 'tua',\n",
              " 'tuas',\n",
              " 'tém',\n",
              " 'tínhamos',\n",
              " 'um',\n",
              " 'uma',\n",
              " 'você',\n",
              " 'vocês',\n",
              " 'vos',\n",
              " 'à',\n",
              " 'às',\n",
              " 'é',\n",
              " 'éramos'}"
            ]
          },
          "execution_count": 104,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "stop_words_pt.add('ainda')\n",
        "stop_words_pt.add('porém')\n",
        "stop_words_pt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "DPGXCql5o093"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "JrI_IoO79UEP"
      },
      "outputs": [],
      "source": [
        "\n",
        "num = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "I3qAefmq85zG",
        "outputId": "498db3de-1edc-483e-f91a-1d054e582d18"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Copyright © 1948 by Sonia Brownell Orwell\n",
            "Copyright © 2009 by Companhia das Letras\n",
            "(edição em língua portuguesa para o Brasil)\n",
            "Título Original: Animal Farm: A Fairy Story\n",
            "T radução: Heitor Aquino Ferreira\n",
            "Revisão: Arlete Sousa e Carmen S. da Costa\n",
            "Or ganização: Adriano T . B. Cruz\n",
            "Arte da Capa: Kiko Farkas e Elisa Cardoso\n",
            "Revisado conforme o novo acordo ortográfico da língua portuguesa.\n",
            "Dados Internacionais de Catalogação na Publicação (CIP)\n",
            "Orwell, Geor ge, 1903-1950\n",
            "A Revolução dos Bichos / Geor ge Orwell ; tradução Heitor Aquino Ferreira – São Paulo :\n",
            "Companhia das Letras, 2009\n",
            "Título original: Animal Farm: A Fairy Story\n",
            "ISBN 978-85-8086-192-1\n",
            "1. Ficção inglesa.\n",
            "2. Título.\n",
            "813                                  CDD 09-04958amavam-no assim , muito\n",
            "embora ele houvesse concorrido na exposição com o nome de\n",
            "“Belo de Willingdon”) gozava de tão alto conceito na granja\n",
            "que todos estavam dispostos a perder uma hora de sono só\n",
            "para ouvi-lo.\n",
            "Ao fundo do grande celeiro, sobre uma espécie de estrado,\n",
            "estava o Major refestelado em sua cama de palha, sob umlampião que pendia da viga. Com doze anos de idade, já bem\n",
            "corpulento, era ainda um porco de porte majestoso, com ar\n",
            "sábio e benevolente, a despeito de suas presas jamais terem\n",
            "sido cortadas. Os outros animais chegavam e punham-se a\n",
            "cômodo, cada qual a seu modo. Os primeiros foram os três\n",
            "cachorros, Branca, Lulu e Cata-Vento, depois os porcos, que se\n",
            "sentaram sobre a palha, em frente ao estrado. As galinhas\n",
            "empoleiraram-se nas janelas, as pombas voaram para os\n",
            "caibros do telhado, as ovelhas e as vacas deitaram-se atrás\n",
            "dos porcos e ali \u0000caram a ruminar. Os dois cavalos de tração,\n",
            "Sansão e Quitéria, chegaram juntos, andando lentamente e\n",
            "pousando no chão os enormes cascos peludos, com grande\n",
            "cuidado para não machucar qualquer animalzinho\n",
            "porventura oculto na palha. Quitéria era uma égua volumosa,\n",
            "matronal, já chegada à meia-idade, cuja silhueta não mais se\n",
            "recompusera após o nascimento do quarto potrinho. Sansão\n",
            "era um bicho enorme, de quase um metro e noventa de\n",
            "altura, forte como dois cavalos. A mancha branca do focinho\n",
            "dava-lhe certo ar de estupidez, e realmente ele não tinha lá\n",
            "uma inteligência de primeira ordem, embora fosse\n",
            "grandemente respeitado pela retidão de caráter e pela\n",
            "tremenda capacidade de trabalho. Depois dos cavalos\n",
            "chegaram Maricota, a cabra branca, e Benjamim , o burro.\n",
            "Benjamim era o animal mais idoso da fazenda, e o mais\n",
            "moderado. Raras vezes falava, e em geral quando o fazia era\n",
            "para emitir uma observação cínica — para dizer, por exemplo,\n",
            "que Deus lhe dera uma cauda para espantar as moscas, e noentanto seria mais do seu agrado não ter nem a cauda nem as\n",
            "moscas. Era o único dos animais que nunca ria. Quando lhe\n",
            "perguntavam por quê, respondia não ver motivo para riso.\n",
            "Não obstante, sem que admitis se abertamente, tinha certa\n",
            "afeição por Sansão; com frequência passavam os domingos\n",
            "juntos no pequeno potreiro existente atrás do pomar,\n",
            "pastando lado a lado em silêncio.\n",
            "Mal se haviam acomodado os dois cavalos quando uma\n",
            "ninhada de patinhos órfãos des\u0000lou celeiro adentro, piando\n",
            "baixinho e procurando um lugar onde não fossem pisoteados.\n",
            "Quitéria protegeu-os com a pata dianteira, e os patinhos ali se\n",
            "aconchegaram, caindo no sono. No último instante, Mimosa,\n",
            "a égua branca, vaidosa e fútil, que puxava a charrete do sr.\n",
            "Jones, entrou, requebrando-se graciosamente e mastigando\n",
            "um torrão de açúcar. Tomou lugar bem à frente e \u0000cou\n",
            "meneando a crina branca, na esperança de chamar atenção\n",
            "para as \u0000tas vermelhas que a adornavam. Por \u0000m, chegou a\n",
            "gata, que buscou, como sempre, o lugar mais morno,\n",
            "en\u0000ando-se entre Sansão e Quitéria; ronronou satisfeita\n",
            "durante toda a fala do Major, sem ouvir uma só palavra.\n",
            "Todos os animais estavam presentes, exceto Moisés, o\n",
            "corvo domesticado, que dormia fora, num poleiro junto à\n",
            "porta dos fundos. Quando o Major os viu, bem acomodados e\n",
            "aguardando atentamente, limpou a garganta e começou:\n",
            "“Camaradas, já ouvistes, por certo, algo a respeito do\n",
            "estranho sonho que tive a noite passada. Mas falarei do sonho\n",
            "mais tarde. Antes, tenho outras coisas a dizer. Sei, camaradas,que não estarei convosco por muito mais tempo, e antes de\n",
            "morrer considero uma obrigação transmitir -vos o que aprendi\n",
            "sobre o mundo. Já vivi bastante, e muito tenho re\u0000etido na\n",
            "solidão da minha pocilga. Creio poder a\u0000rmar que\n",
            "compreendo a natureza da vida sobre esta terra tão bem\n",
            "quanto qualquer outro animal vivente. É sobre o que desejo\n",
            "vos falar.\n",
            "“Então, camaradas, qual é a natureza desta nossa vida?\n",
            "Enfrentemos a realidade: nossa vida é miserável, trabalhosa e\n",
            "curta. Nascemos, recebemos o mínimo alimento necessário\n",
            "para continuar respirando, e os que podem trabalhar são\n",
            "exigidos até a última parcela de suas forças; no instante em\n",
            "que nossa utilidade acaba, trucidam-nos com hedionda\n",
            "crueldade. Nenhum animal na Inglaterra sabe o que é\n",
            "felicidade ou lazer após completar um ano de vida. Nenhum\n",
            "animal na Inglaterra é livre. A vida do animal é feita de\n",
            "miséria e escravidão: essa é a verdade nua e crua.\n",
            "“Será isso, apenas, a ordem natural das coisas? Será esta\n",
            "nossa terra tão pobre que não ofereça condições de vida\n",
            "decente aos seus habitantes? Não, camaradas, mil vezes não!\n",
            "O solo da Inglaterra é fértil, o clima é bom, ela pode dar\n",
            "alimento em abundância a um número de animais\n",
            "muitíssimo maior do que o existente. Só esta nossa fazenda\n",
            "comportaria uma dúzia de cavalos, umas vinte vacas,\n",
            "centenas de ovelhas — vivendo todos num conforto e com\n",
            "uma dignidade que agora estão além de nossa imaginação.\n",
            "Por que, então, permanecemos nesta miséria? Porque quasetodo o produto do nosso esforço nos é roubado pelos seres\n",
            "humanos. Eis aí, camaradas, a resposta a todos os nossos\n",
            "problemas. Resume-se em uma só palavra — Homem. O\n",
            "Homem é o nosso verdadeiro e único inimigo. Retire-se da\n",
            "cena o Homem e a causa principal da fome e da sobrecarga de\n",
            "trabalho desaparecerá para sempre.\n",
            "“O Homem é a única criatura que consome sem produzir.\n",
            "Não dá leite, não põe ovos, é fraco demais para puxar o arado,\n",
            "não corre o que dê para pegar uma lebre. Mesmo assim, é o\n",
            "senhor de todos os animais. Põe-nos a mourejar, dá-nos de\n",
            "volta o mínimo para evitar a inanição e \u0000ca com o restante.\n",
            "Nosso trabalho amanha o solo, nosso estrume o fertiliza, e no\n",
            "entanto nenhum de nós possui mais que a própria pele. As\n",
            "vacas, que aqui vejo à minha frente, quantos litros de leite\n",
            "terão produzido neste ano? E que aconteceu a esse leite, que\n",
            "poderia estar alimentando robustos bezerrinhos? Desceu pela\n",
            "garganta dos nossos inimigos. E as galinhas, quantos ovos\n",
            "puseram neste ano, e quantos se transformaram em\n",
            "pintinhos? Os restantes foram para o mercado, fazer dinheiro\n",
            "para Jones e seus homens. E você, Quitéria, diga-me onde\n",
            "estão os quatro potrinhos que deveriam ser o apoio e o prazer\n",
            "da sua velhice. Foram vendidos com a idade de um ano —\n",
            "nunca mais você os verá. Como paga por seus quatro partos e\n",
            "por todo o seu trabalho no campo, que recebeu você, além de\n",
            "ração e baia?\n",
            "“Mesmo miserável como é, nossa vida não chega nem ao\n",
            "\u0000m de modo natural. Não me queixo por mim , que tive atémuita sorte. Estou com doze anos e sou pai de mais de\n",
            "quatrocentos porcos. Isto é a vida normal de um barrão. Mas\n",
            "no \u0000m nenhum animal escapa ao cutelo. Vós, jovens leitões\n",
            "que estais sentados à minha frente, não escapareis de\n",
            "guinchar no cepo dentro de um ano. Todos chegaremos a esse\n",
            "horror, as vacas, os porcos, as galinhas, as ovelhas, todos.\n",
            "Nem mesmo os cavalos e os cachorros escapam a esse\n",
            "destino. Sansão, no dia em que seus músculos fortes\n",
            "perderem a rigidez, Jones o mandará para o carniceiro, e você\n",
            "será degolado e fervido para alimentar os cães de caça.\n",
            "Quanto aos cachorros, depois de velhos e desdentados, Jones\n",
            "amarra-lhes uma pedra ao pescoço e os atira na primeira\n",
            "lagoa.\n",
            "“Não está, pois, claro como água, camaradas, que todos os\n",
            "males da nossa existência têm origem na tirania dos\n",
            "humanos? Basta que nos livremos do Homem para que o\n",
            "produto de nosso trabalho seja só nosso. Praticamente, da\n",
            "noite para o dia, poderíamos nos tornar ricos e livres. Que\n",
            "fazer, então? Trabalhar dia e noite, de corpo e alma, para a\n",
            "derrubada do gênero humano. Esta é a mensagem que eu vos\n",
            "trago, camaradas: rebelião! Não sei dizer quando será esta\n",
            "revolução, pode ser daqui a uma semana ou daqui a um\n",
            "século, mas uma coisa eu sei, tão certo quanto vejo esta palha\n",
            "sob meus pés: mais cedo ou mais tarde, justiça será feita.\n",
            "Fixai isso, camaradas, para o resto de vossas curtas vidas! E,\n",
            "sobretudo, transmiti esta minha mensagem aos que virãodepois de vós, para que as futuras gerações continuem na luta\n",
            "até a vitória.\n",
            "“E lembrai-vos, camaradas, jamais deixai fraquejar vossa\n",
            "decisão. Nenhum argumento vos poderá desviar. Fechai os\n",
            "ouvidos quando vos disserem que o Homem e os animais têm\n",
            "interesses comuns, que a prosperidade de um é a\n",
            "prosperidade dos outros. É tudo mentira. O Homem não busca\n",
            "interesses que não os dele próprio. Que haja entre nós,\n",
            "animais, uma perfeita unidade, uma perfeita camaradagem\n",
            "na luta. Todos os homens são inimigos, todos os animais são\n",
            "camaradas.”\n",
            "Nesse momento houve uma tremenda confusão.\n",
            "Enquanto o Major falava, quatro ratos haviam rastejado para\n",
            "fora de seus buracos e estavam sentados nas patinhas de trás,\n",
            "a ouvi-lo. De repente, os cachorros lhes deram pela presença,\n",
            "e somente pela rapidez com que sumiram nos buracos foi que\n",
            "os ratos conseguiram escapar com vida. O Major levantou a\n",
            "pata, pedindo silêncio.\n",
            "“Camaradas”, disse ele, “eis aí um ponto que precisa ser\n",
            "esclarecido. As criaturas rebeldes, tais como os ratos e os\n",
            "coelhos, serão nossos amigos ou nossos inimigos?\n",
            "Coloquemos o assunto em votação. Apresento à assembleia a\n",
            "seguinte questão: são os ratos camaradas?”\n",
            "A votação foi realizada imediatamente, e concluiu-se, por\n",
            "esmagadora maioria, que os ratos eram camaradas. Houve\n",
            "apenas quatro votos contra, dos três cachorros e da gata, que,depois se descobriu, votara pelos dois lados. O Major\n",
            "prosseguiu:\n",
            "“Pouco mais tenho a dizer. Repito apenas: lembrai-vos\n",
            "sempre do vosso dever de inimizade para com o Homem e\n",
            "todos os seus desígnios. O que quer que ande sobre duas\n",
            "pernas é inimigo, o que quer que ande sobre quatro pernas,\n",
            "ou tenha asas, é amigo. Lembrai-vos também de que na luta\n",
            "contra o Homem não devemos ser como ele. Mesmo  quando o\n",
            "tenhais derrotado, evitai-lhe os vícios. Animal nenhum deve\n",
            "morar em casas, nem dormir em camas, nem usar roupas,\n",
            "nem beber álcool, nem fumar, nem tocar em dinheiro, nem\n",
            "comerciar. Todos os hábitos do Homem são maus. E\n",
            "principalmente, jamais um animal deverá tiranizar outros\n",
            "animais. Fortes ou fracos, espertos ou simplórios, somos\n",
            "todos irmãos. Todos os animais são iguais.\n",
            "“E agora, camaradas, vou contar-vos o sonho que tive na\n",
            "noite passada. Não sei o que signi\u0000ca. Foi um sonho sobre\n",
            "como será o mundo quando o Homem desaparecer. Mas\n",
            "lembrou-me algo que havia muito eu esquecera. Há anos,\n",
            "quando eu ainda era um leitãozinho, minha mãe e as outras\n",
            "porcas costumavam cantar uma antiga canção da qual só\n",
            "conheciam a melodia e as três primeiras palavras. Na minha\n",
            "infância aprendi a melodia, depois a esqueci. Na noite\n",
            "passada, entretanto, ela me voltou à memória. O mais\n",
            "interessante é que me lembrei também dos versos — os\n",
            "quais, tenho certeza, foram cantados pelos animais de\n",
            "antanho, depois esquecidos por muitas gerações. Vou cantaressa canção, camaradas. Estou velho, e minha voz é rouca,\n",
            "mas quando vos houver ensinado a melodia, podereis cantá-\n",
            "la melhor que eu. Chama-se ‘Bichos da Inglaterra’.”\n",
            "O velho Major limpou a garganta e começou a cantar. De\n",
            "fato, a voz era roufenha, mas ele entoava bem, e a melodia\n",
            "era bastante movimentada, algo entre “Clementine” e “La\n",
            "cucaracha”. Os versos diziam:\n",
            " \n",
            "Bichos da Inglaterra e da Irlanda,\n",
            "Daqui, dali, de acolá,\n",
            "Escutai a alvissareira\n",
            "Novidade que virá.\n",
            " \n",
            "Mais hoje, mais amanhã,\n",
            "O Tirano vem ao chão,\n",
            "E os campos da Inglaterra\n",
            "Só os bichos pisarão.\n",
            " \n",
            "Não mais argolas nas ventas,\n",
            "Dorsos livres dos arreios,\n",
            "Freio e espora enferrujando\n",
            "E relho em cantos alheios.\n",
            " \n",
            "Riqueza incomensurável,\n",
            "Terra boa, muito grão,\n",
            "Trigo, cevada e aveia,\n",
            "Pastagem, feno e feijão.\n",
            " \n",
            "Lindos campos da Inglaterra,Ribeiros com águas puras,\n",
            "Brisas leves circulando,\n",
            "Liberdade nas alturas.\n",
            " \n",
            "Lutemos por esse dia\n",
            "Mesmo que nos custe a vida.\n",
            "Gansos, vacas e cavalos,\n",
            "Todos unidos na lida.\n",
            " \n",
            "Bichos da Inglaterra e da Irlanda,\n",
            "Daqui, dali, de acolá,\n",
            "Levai esta minha mensagem\n",
            "E o futuro sorrirá.\n",
            " \n",
            "O canto levou a bicharada à mais extrema excitação.\n",
            "Mesmo antes de o Major chegar ao \u0000m, já haviam começado a\n",
            "cantar por conta própria. Até os mais parvos pegaram a\n",
            "melodia e algumas palavras; os mais vivos, tais como os\n",
            "porcos e os cachorros, decoraram a canção em minutos.\n",
            "Então, depois de algumas tentativas, a granja toda atacou\n",
            "“Bichos da Inglaterra” em potente uníssono. As vacas mugiam\n",
            "a canção, os cachorros latiam, as ovelhas baliam, os cavalos\n",
            "relinchavam, os patos grasnavam. Foi tal o enlevo que\n",
            "cantaram cinco vezes corridas, de ponta a ponta, e teriam\n",
            "cantado a noite toda se não fossem interrompidos.\n",
            "Infelizmente, o alarido acordou Jones, que pulou da cama\n",
            "certo de que havia raposa no pátio. Deitou a mão na\n",
            "espingarda, sempre pronta num canto do quarto, e disparouuma carga de chumbo grosso na escuridão. O chumbo foi\n",
            "encravar-se na parede do celeiro, e a reunião dispersou-se\n",
            "num abrir e fechar de olhos. Cada qual correu para seu pouso.\n",
            "As aves saltaram para os poleiros, o gado deitou-se na palha\n",
            "e, em poucos instantes, toda a fazenda dormia.\n",
            "*\n"
          ]
        }
      ],
      "source": [
        "# filecontent = \"\"\n",
        "with open(PATH + f'txt_cap{num}.txt', 'r', encoding='utf8') as f:\n",
        "    filecontent = f.read()\n",
        "\n",
        "print(filecontent[0:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YhFpt8aS851e",
        "outputId": "ae59b9f6-eb7d-46b1-b67e-d90d87a45aa2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "str"
            ]
          },
          "execution_count": 108,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(filecontent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AjbsQhUP8532",
        "outputId": "2a4fb3cb-83ef-4f68-afdd-6b014a95b7b1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "13464"
            ]
          },
          "execution_count": 109,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(filecontent) # número de tokens"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vlfw_eEunfEU"
      },
      "source": [
        "## Transformando o texto completo em sentenças (tokenizer do NLTK)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "id": "_MtaoKJj856Y"
      },
      "outputs": [
        {
          "ename": "LookupError",
          "evalue": "\n**********************************************************************\n  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt_tab')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\samug/nltk_data'\n    - 'c:\\\\Program Files\\\\Python311\\\\nltk_data'\n    - 'c:\\\\Program Files\\\\Python311\\\\share\\\\nltk_data'\n    - 'c:\\\\Program Files\\\\Python311\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\samug\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mLookupError\u001b[39m                               Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[110]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m sentencas = []\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m sentence \u001b[38;5;129;01min\u001b[39;00m \u001b[43msent_tokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilecontent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlanguage\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43menglish\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m:\n\u001b[32m      3\u001b[39m     sentencas.append(sentence)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\nltk\\tokenize\\__init__.py:119\u001b[39m, in \u001b[36msent_tokenize\u001b[39m\u001b[34m(text, language)\u001b[39m\n\u001b[32m    109\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msent_tokenize\u001b[39m(text, language=\u001b[33m\"\u001b[39m\u001b[33menglish\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    110\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    111\u001b[39m \u001b[33;03m    Return a sentence-tokenized copy of *text*,\u001b[39;00m\n\u001b[32m    112\u001b[39m \u001b[33;03m    using NLTK's recommended sentence tokenizer\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    117\u001b[39m \u001b[33;03m    :param language: the model name in the Punkt corpus\u001b[39;00m\n\u001b[32m    118\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m119\u001b[39m     tokenizer = \u001b[43m_get_punkt_tokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlanguage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    120\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m tokenizer.tokenize(text)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\nltk\\tokenize\\__init__.py:105\u001b[39m, in \u001b[36m_get_punkt_tokenizer\u001b[39m\u001b[34m(language)\u001b[39m\n\u001b[32m     96\u001b[39m \u001b[38;5;129m@functools\u001b[39m.lru_cache\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_punkt_tokenizer\u001b[39m(language=\u001b[33m\"\u001b[39m\u001b[33menglish\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m     98\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     99\u001b[39m \u001b[33;03m    A constructor for the PunktTokenizer that utilizes\u001b[39;00m\n\u001b[32m    100\u001b[39m \u001b[33;03m    a lru cache for performance.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    103\u001b[39m \u001b[33;03m    :type language: str\u001b[39;00m\n\u001b[32m    104\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m105\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPunktTokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlanguage\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\nltk\\tokenize\\punkt.py:1744\u001b[39m, in \u001b[36mPunktTokenizer.__init__\u001b[39m\u001b[34m(self, lang)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, lang=\u001b[33m\"\u001b[39m\u001b[33menglish\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m   1743\u001b[39m     PunktSentenceTokenizer.\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1744\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mload_lang\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlang\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\nltk\\tokenize\\punkt.py:1749\u001b[39m, in \u001b[36mPunktTokenizer.load_lang\u001b[39m\u001b[34m(self, lang)\u001b[39m\n\u001b[32m   1746\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload_lang\u001b[39m(\u001b[38;5;28mself\u001b[39m, lang=\u001b[33m\"\u001b[39m\u001b[33menglish\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m   1747\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnltk\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m find\n\u001b[32m-> \u001b[39m\u001b[32m1749\u001b[39m     lang_dir = \u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtokenizers/punkt_tab/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mlang\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m/\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1750\u001b[39m     \u001b[38;5;28mself\u001b[39m._params = load_punkt_params(lang_dir)\n\u001b[32m   1751\u001b[39m     \u001b[38;5;28mself\u001b[39m._lang = lang\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\nltk\\data.py:579\u001b[39m, in \u001b[36mfind\u001b[39m\u001b[34m(resource_name, paths)\u001b[39m\n\u001b[32m    577\u001b[39m sep = \u001b[33m\"\u001b[39m\u001b[33m*\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m70\u001b[39m\n\u001b[32m    578\u001b[39m resource_not_found = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m579\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(resource_not_found)\n",
            "\u001b[31mLookupError\u001b[39m: \n**********************************************************************\n  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt_tab')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\samug/nltk_data'\n    - 'c:\\\\Program Files\\\\Python311\\\\nltk_data'\n    - 'c:\\\\Program Files\\\\Python311\\\\share\\\\nltk_data'\n    - 'c:\\\\Program Files\\\\Python311\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\samug\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n"
          ]
        }
      ],
      "source": [
        "sentencas = []\n",
        "for sentence in sent_tokenize(filecontent, language=\"english\"):\n",
        "    sentencas.append(sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vxJaa-rChuua",
        "outputId": "a99f39f8-68bd-4128-f198-99cd3df7f399"
      },
      "outputs": [],
      "source": [
        "sentencas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ec5WwG_o9_OH",
        "outputId": "d8f085be-533e-4d44-a9f2-d91902ecf1d5"
      },
      "outputs": [],
      "source": [
        "index = 1\n",
        "for sentenca in sentencas[0:100]: # mostrando as 100 primeiras\n",
        "    print(f'{index}: {sentenca}')\n",
        "    index+=1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_A8vaP0nwjs"
      },
      "source": [
        "## Segmentação por quebra de linha e depois pelo tokenizer do NLTK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x4J8rh4r9_Q2"
      },
      "outputs": [],
      "source": [
        "sentencas_linha = []\n",
        "for sentence in filecontent.split('\\n'):\n",
        "    if sentence != '':\n",
        "        for processed_sentence in sent_tokenize(sentence, language = 'portuguese'):\n",
        "            sentencas_linha.append(processed_sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xLkMb9909_TX",
        "outputId": "13095862-420a-49dc-e0d9-edf850aaf48c"
      },
      "outputs": [],
      "source": [
        "index = 1\n",
        "for sentenca in sentencas_linha[0:100]: # mostrando as 100 primeiras\n",
        "    print(f'{index}: {sentenca}')\n",
        "    index+=1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCY0nduvn6RD"
      },
      "source": [
        "## Tokenização de cada sentença em palavras (tokenizer do NLTK)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "piYgw2kZ9_V4",
        "outputId": "900136f6-5e0e-46d5-9fbb-9c9e4bb4b77e"
      },
      "outputs": [],
      "source": [
        "sentencas_tokenizadas = []\n",
        "\n",
        "for sentenca in sentencas_linha:\n",
        "    tokenized_sentence = word_tokenize(sentenca, language='portuguese')\n",
        "    sentencas_tokenizadas.append(tokenized_sentence)\n",
        "index = 1\n",
        "for tokens in sentencas_tokenizadas[0:100]: # mostrando as 100 primeiras\n",
        "    print(f'{index}: {tokens}')\n",
        "    index+=1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2x5_qyeYoQ7r"
      },
      "source": [
        "## Pre-processamento dos elementos tokenizados\n",
        "A ideia aqui é retirar todas as palavras que pertencem a lista de stopwords, deixar tudo em minúsculos, retirar espaços e quebras de linhas adicionais desnecessários."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "A-HP3N7O9_Yz",
        "outputId": "8659fbd5-55d5-4d68-ad6b-44d12d8b4617"
      },
      "outputs": [],
      "source": [
        "from typing import TextIO\n",
        "sent_tokenizada_preprocessed = []\n",
        "for sent_tokenizada in sentencas_tokenizadas:\n",
        "    raw = [token.lower() for token in sent_tokenizada]\n",
        "\n",
        "    raw = [''.join(c for c in s if c not in remove_pt+'–'+'🙁'+'\\’'+'\\”'+\"“\") for s in raw]\n",
        "    raw = [re.sub(r\"\\d+[.,]?\\d*\",\"\", s) for s in raw]\n",
        "    raw = [s for s in raw if s not in stop_words_pt] # stopwords\n",
        "    raw = [' '.join(s.split()) for s in raw if s]\n",
        "    string = ' '.join(raw).rstrip().lstrip()\n",
        "    if string != '':\n",
        "        sent_tokenizada_preprocessed.append(string)\n",
        "\n",
        "index = 1\n",
        "for texto in sent_tokenizada_preprocessed[0:100]: # mostrando as 100 primeiras\n",
        "    print(f'{index}: {texto}')\n",
        "    index+=1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c19OVc3J-QCI"
      },
      "source": [
        "#NGramas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1bzpq3ZjQ6wq",
        "outputId": "7ed09653-231b-4f41-9592-ac1c6781cf26"
      },
      "outputs": [],
      "source": [
        "len(sent_tokenizada_preprocessed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "X5PYm2nP-Qey",
        "outputId": "c4cf8b16-bc92-4736-8a6d-03f2c81a8fae"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "ngram_value = 1\n",
        "most_common_value = 100\n",
        "\n",
        "ngram_counts = [list(ngrams(s.split(), ngram_value)) for s in sent_tokenizada_preprocessed]\n",
        "flat_ngram_counts = [item for sublist in ngram_counts for item in sublist]\n",
        "ngram_list = Counter(flat_ngram_counts)\n",
        "\n",
        "common = ngram_list.most_common(most_common_value)\n",
        "\n",
        "df_common = pd.DataFrame(common, columns = ['Ngram','Count'])\n",
        "index = 1\n",
        "for n_gram in ngram_counts[0:100]: # mostrando as 100 primeiras\n",
        "    print(f'{index}: {n_gram}')\n",
        "    index+=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "x6a0Xr-9AfQJ",
        "outputId": "f8473b80-ec0a-4f5e-88cb-ea676201f981"
      },
      "outputs": [],
      "source": [
        "index = 1\n",
        "for n_gram in flat_ngram_counts[0:100]: # mostrando as 100 primeiras\n",
        "    print(f'{index}: {n_gram}')\n",
        "    index+=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HkSJN6XtAfTa",
        "outputId": "f095f11a-aa99-4278-b7ea-a5d39f16c6ac"
      },
      "outputs": [],
      "source": [
        "len(ngram_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WEfEcOb0AfWp"
      },
      "outputs": [],
      "source": [
        "common"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7CTVGLB1AfZr"
      },
      "outputs": [],
      "source": [
        "df_common.head(30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B3WItXZiBLCC",
        "outputId": "0d466b96-2fbf-4484-fded-7df833381d0f"
      },
      "outputs": [],
      "source": [
        "# Quantidade de palavras\n",
        "len(flat_ngram_counts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2YG_UDDhBLE0",
        "outputId": "9e721639-34c0-414e-e2e8-86ddff4df17a"
      },
      "outputs": [],
      "source": [
        "# Quantidade de palavras únicas\n",
        "len(ngram_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 775
        },
        "id": "228Cxt6WBLHY",
        "outputId": "e12cbda5-6828-4944-cf5f-cae9e8d50b28"
      },
      "outputs": [],
      "source": [
        "color = 'black'\n",
        "height = 400\n",
        "width = 800\n",
        "max_words = 2000\n",
        "colormap = 'prism'\n",
        "size_X = 50\n",
        "size_Y = 50\n",
        "\n",
        "str_text=\" \".join(sent_tokenizada_preprocessed)\n",
        "\n",
        "\n",
        "wordcloud = WordCloud(background_color = color, max_words = max_words, max_font_size = 90, colormap = colormap, height = height, width = width).generate(str_text)\n",
        "\n",
        "X = size_X/2.54\n",
        "Y = size_Y/2.25\n",
        "\n",
        "fig = plt.figure(figsize = [X, Y])\n",
        "plt.imshow(wordcloud, interpolation = \"bilinear\")\n",
        "plt.axis(\"off\")\n",
        "plt.box(False)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fkYVN95Q5D7I"
      },
      "source": [
        "fazer a frequencia, Carlos"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
